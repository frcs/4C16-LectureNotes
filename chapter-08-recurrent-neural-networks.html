<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Recurrent Neural Networks – 4C16 - Deep Learning and its Applications</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter-09-generative-models.html" rel="next">
<link href="./chapter-07-advances-in-network-architectures.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-07-advances-in-network-architectures.html">Modern Architectures and Techniques</a></li><li class="breadcrumb-item"><a href="./chapter-08-recurrent-neural-networks.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">4C16 - Deep Learning and its Applications</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module Descriptor</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-00-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-01-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Linear Regression and Least Squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-02-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Logistic Regression: From Lines to Probabilities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-03-classic-classifiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">A Tour of Classic Classifiers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-04-evaluating-classifier-performance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evaluating Classifier Performance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundations of Deep Neural Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-05-deep-feedforward-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Feedforward Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-06-convolutional-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Modern Architectures and Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-07-advances-in-network-architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advances in Network Architectures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-08-recurrent-neural-networks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-09-generative-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">An Introduction to Generative Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-10-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Attention Mechanism and Transformers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-11-LLMs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Large Language Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./note-01-error-loss-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Relationship between Error, Loss Function and Maximum Likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./note-02-universal-approximation-theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Universal Approximation Theorem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./note-03-l1-induces-sparsity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Why Does <span class="math inline">L_1</span> Regularisation Induce Sparsity?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./note-04-kernel-trick.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Kernel Trick</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./note-05-He-initialisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">He Initialisation</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#a-feedforward-network-unrolled-over-time" id="toc-a-feedforward-network-unrolled-over-time" class="nav-link active" data-scroll-target="#a-feedforward-network-unrolled-over-time"><span class="header-section-number">8.1</span> A Feedforward Network Unrolled Over Time</a></li>
  <li><a href="#application-example-character-level-language-modelling" id="toc-application-example-character-level-language-modelling" class="nav-link" data-scroll-target="#application-example-character-level-language-modelling"><span class="header-section-number">8.2</span> Application Example: Character-Level Language Modelling</a>
  <ul class="collapse">
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  </ul></li>
  <li><a href="#training-back-propagation-through-time" id="toc-training-back-propagation-through-time" class="nav-link" data-scroll-target="#training-back-propagation-through-time"><span class="header-section-number">8.3</span> Training: Back-Propagation Through Time</a></li>
  <li><a href="#dealing-with-long-sequences" id="toc-dealing-with-long-sequences" class="nav-link" data-scroll-target="#dealing-with-long-sequences"><span class="header-section-number">8.4</span> Dealing with Long Sequences</a>
  <ul class="collapse">
  <li><a href="#lstm" id="toc-lstm" class="nav-link" data-scroll-target="#lstm"><span class="header-section-number">8.4.1</span> LSTM</a></li>
  <li><a href="#gru" id="toc-gru" class="nav-link" data-scroll-target="#gru"><span class="header-section-number">8.4.2</span> GRU</a></li>
  <li><a href="#gated-units" id="toc-gated-units" class="nav-link" data-scroll-target="#gated-units"><span class="header-section-number">8.4.3</span> Gated Units</a></li>
  </ul></li>
  <li><a href="#application-image-caption-generator" id="toc-application-image-caption-generator" class="nav-link" data-scroll-target="#application-image-caption-generator"><span class="header-section-number">8.5</span> Application: Image Caption Generator</a></li>
  <li><a href="#takeaways" id="toc-takeaways" class="nav-link" data-scroll-target="#takeaways"><span class="header-section-number">8.6</span> Takeaways</a></li>
  <li><a href="#limitations-of-rnns-and-the-rise-of-transformers" id="toc-limitations-of-rnns-and-the-rise-of-transformers" class="nav-link" data-scroll-target="#limitations-of-rnns-and-the-rise-of-transformers"><span class="header-section-number">8.7</span> Limitations of RNNs and the Rise of Transformers</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-07-advances-in-network-architectures.html">Modern Architectures and Techniques</a></li><li class="breadcrumb-item"><a href="./chapter-08-recurrent-neural-networks.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Recurrent Neural Networks (RNNs) are a specialised type of neural architecture designed to process <strong>sequential data</strong>. Unlike traditional feedforward networks, which process inputs independently, RNNs possess a form of memory that allows them to retain information from previous inputs in a sequence to inform future predictions.</p>
<section id="a-feedforward-network-unrolled-over-time" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="a-feedforward-network-unrolled-over-time"><span class="header-section-number">8.1</span> A Feedforward Network Unrolled Over Time</h2>
<p>Sequential data appears in many domains. Obvious examples include time series such as audio signals, stock market prices, or a vehicle’s trajectory. Text, which is a sequence of words or characters, is another prime example. In fact, RNNs were particularly successful in machine translation tasks during the early phase of the deep learning revolution.</p>
<p>At its core, an RNN works by recursively applying a function to each element of a sequence. The network maintains a hidden state, or context, which is updated at each step. This context captures information from all previous steps. As shown in <a href="#fig-rnn-rec-def" class="quarto-xref">Figure&nbsp;<span>8.1</span></a>, this architecture is traditionally represented using a feedback loop in the graph.</p>
<div id="fig-rnn-rec-def" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-rec-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-rec-def.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-rec-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: A Recurrent Neural Network shown in its compact, recursive form.
</figcaption>
</figure>
</div>
<p>The input stream, denoted by <span class="math inline">{\bf x}</span>, feeds into the context layer, denoted by <span class="math inline">{\bf h}</span>. This layer then re-uses the previously computed context, <span class="math inline">{\bf h}_{t-1}</span>, along with the current input, <span class="math inline">{\bf x}_t</span>, to compute the new context, <span class="math inline">{\bf h}_t</span>, and the output, <span class="math inline">{\bf y}_t</span>.</p>
<p>For those with a background in signal processing, an analogy can be drawn: if convolutional layers are akin to Finite Impulse Response (FIR) filters, then RNNs are similar to Infinite Impulse Response (IIR) filters, as they incorporate feedback from previous states.</p>
<p>To better understand how an RNN operates, we can “unroll” or “unfold” the recursive loop (see <a href="#fig-rnn-def-unrolled" class="quarto-xref">Figure&nbsp;<span>8.2</span></a>). This reveals a deep feedforward network where each layer corresponds to a single time step in the sequence.</p>
<div id="fig-rnn-def-unrolled" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-def-unrolled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-rec-def-unrolled.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-def-unrolled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: The same Recurrent Neural Network in its unrolled, feedforward form.
</figcaption>
</figure>
</div>
<p>A key characteristic of RNNs is that the network parameters (weights and biases) are shared across all time steps. This means we use the same set of weights, <span class="math inline">w</span>, at every iteration. This parameter sharing makes the network efficient, as it does not need to learn a new set of parameters for each point in the sequence, and it allows the model to generalise to sequences of varying lengths.</p>
<div id="fig-SimpleRNN" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-SimpleRNN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-ctx-layer.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-SimpleRNN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: In a simple RNN, the hidden layer is a standard fully connected layer.
</figcaption>
</figure>
</div>
<p><a href="#fig-SimpleRNN" class="quarto-xref">Figure&nbsp;<span>8.3</span></a> shows an RNN in its most basic form, often called a <strong>simple RNN</strong> or an <strong>Elman network</strong>, where the hidden layer is simply a dense layer of neurons with a <span class="math inline">\mathrm{tanh}</span> activation function.</p>
<p>We typically use a <span class="math inline">\mathrm{tanh}</span> activation because its output ranges from -1 to 1. This allows the hidden state’s values to both increase and decrease.</p>
<p>The governing equations for a simple RNN at a time step <span class="math inline">t</span> are:</p>
<p><span class="math display">\begin{equation}
\begin{aligned}
{\bf h}_{t}&amp;=\tanh({\bf W}_{h}{\bf x}_{t}+{\bf U}_{h}{\bf h}_{t-1}+{\bf
b}_{h})\\
{\bf y}_{t}&amp;=\sigma _{y}({\bf W}_{y}{\bf h}_{t}+{\bf b}_{y})
\end{aligned}
\end{equation}</span></p>
<p>Here, <span class="math inline">{\bf x}_t</span> is the input vector at time <span class="math inline">t</span>, <span class="math inline">{\bf h}_t</span> is the hidden state vector, and <span class="math inline">{\bf y}_t</span> is the output vector. The matrices <span class="math inline">{\bf W}_{h}</span>, <span class="math inline">{\bf U}_{h}</span>, and <span class="math inline">{\bf W}_{y}</span>, along with the bias vectors <span class="math inline">{\bf b}_{h}</span> and <span class="math inline">{\bf b}_{y}</span>, are the parameters that the network learns. Note that these parameters are the same for all time steps. <span class="math inline">\sigma_y</span> is the activation function for the output layer, chosen based on the specific task (e.g., softmax for classification).</p>
<p>In PyTorch, we can define a simple RNN layer with <code>nn.RNN</code>. The input shape is typically <code>(n, p)</code>, where <code>n</code> is the number of time steps in the sequence and <code>p</code> is the number of features at each time step.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> nn.RNN(input_size<span class="op">=</span><span class="dv">10</span>, hidden_size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">input</span> <span class="op">=</span> torch.randn(<span class="dv">30</span>, <span class="dv">10</span>) <span class="co"># seq length = 30, nb features = 10</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>h0 <span class="op">=</span> torch.randn( <span class="dv">1</span>, <span class="dv">20</span>)    <span class="co"># context vector size = 20</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>output, hn <span class="op">=</span> rnn(<span class="bu">input</span>, h0) </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>output.shape                <span class="co"># torch.Size([30, 20]) </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># output seq has length 30, with 20 features</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In practice, we would define it through a class as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleRNNModel(nn.Module):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, p, hsize, osize):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleRNNModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the RNN and Linear layers</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.RNN(p, hsize, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hsize, osize)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># returns the hidden state for every time step.</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        output_sequence, _ <span class="op">=</span> <span class="va">self</span>.rnn(x)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass the full sequence to the linear layer</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(output_sequence)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.softmax(output, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage:</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># model = SimpleRNNModel(p=p, hsize=hsize, osize=osize)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here the RNN layer returns the full sequence of hidden states, ie. one for each time step. <a href="#fig-rnn-return-sequence" class="quarto-xref">Figure&nbsp;<span>8.4</span></a> illustrates this. The SimpleRNN layer outputs the hidden state for each time step. This is useful for sequence-to-sequence tasks, such as machine translation or speech recognition, where we need an output at each step of the sequence.</p>
<div id="fig-rnn-return-sequence" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-return-sequence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-2.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-return-sequence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: An unrolled RNN layer that returns the full sequence of hidden states.
</figcaption>
</figure>
</div>
<p>An alternative shown in <a href="#fig-rnn-no-return-sequence" class="quarto-xref">Figure&nbsp;<span>8.5</span></a> is when the RNN layer outputs only the hidden state from the very last time step. This is common when we need a single summary representation of the entire sequence, for instance, in a classification task where this final state is fed into a dense layer to predict a label for the whole sequence.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleRNNModel2(nn.Module):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, p, hs, os):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleRNNModel2, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.RNN(p, hs, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hs, os)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The RNN layer gives us the full sequence</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        output_sequence, _ <span class="op">=</span> <span class="va">self</span>.rnn(x)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Here we select the output of the final time step.</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># `[:, -1, :]` does this.</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        last_hidden_state <span class="op">=</span> output_sequence[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass only the final hidden state to the linear layer</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(last_hidden_state)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.softmax(output, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage:</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># model = SimpleRNNModel2(p=p, hs=hs, os=os)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-rnn-no-return-sequence" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-no-return-sequence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-1.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-no-return-sequence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.5: An unrolled RNN layer that returns only the final hidden state.
</figcaption>
</figure>
</div>
<p>Note that we can stack multiple RNN layers, much like we stack convolutional layers in a CNN. For instance:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StackedRNNModel(nn.Module):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, p, hs, ks, os):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(StackedRNNModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the two RNN layers and the final linear layer</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn1 <span class="op">=</span> nn.RNN(p, hs, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn2 <span class="op">=</span> nn.RNN(hs, ks, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(ks, os)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the full output sequence from the first RNN layer</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        output1, _ <span class="op">=</span> <span class="va">self</span>.rnn1(x)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass that sequence to the second RNN layer</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        output2, _ <span class="op">=</span> <span class="va">self</span>.rnn2(output1)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Take the final hidden state from the last layer's output</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        last_hidden_state <span class="op">=</span> output2[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass it to the linear layer for classification</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(last_hidden_state)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.softmax(output, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage:</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># model = StackedRNNModel(p=feature_size, hs=hs, ks=ks, os=os)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This results in the deep architecture illustrated in <a href="#fig-rnn-stacking" class="quarto-xref">Figure&nbsp;<span>8.6</span></a>.</p>
<div id="fig-rnn-stacking" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-stacking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-3.svg" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-stacking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.6: An example of how multiple RNN layers can be stacked.
</figcaption>
</figure>
</div>
</section>
<section id="application-example-character-level-language-modelling" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="application-example-character-level-language-modelling"><span class="header-section-number">8.2</span> Application Example: Character-Level Language Modelling</h2>
<p>Let us explore a classic application of RNNs: building a character-level language model. The goal is to predict the next character in a piece of text, given the sequence of preceding characters. This is, in essence, our first look at a generative language model. The core idea is to train an RNN on a large corpus of text and have it learn the underlying statistical patterns of the language.</p>
<section id="training" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="training">Training</h3>
<p>First, we must convert the text characters into a numerical format that the network can process. A common method is one-hot encoding, where each unique character in the vocabulary is represented by a binary vector with a single ‘1’ at the index corresponding to that character, and ’0’s everywhere else.</p>
<p>The training process is framed as a classification task. We feed the network a sequence of characters, for example <span class="math inline">{\bf x}_1, \dots, {\bf
x}_{n-1}</span>, and train it to predict the next character, <span class="math inline">{\bf y} = {\bf
x}_{n}</span>. The network’s output layer will typically use a softmax activation function, which produces a probability distribution over the entire vocabulary for the next character. The loss function used for training is usually cross-entropy.</p>
<div id="fig-rnn-4" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-4.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.7: An unrolled RNN used for next-character prediction.
</figcaption>
</figure>
</div>
<p>So, the training objective is simple: given a sequence of previous characters, can the network accurately predict the character that comes next?</p>
</section>
<section id="inference" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="inference">Inference</h3>
<p>Once the RNN is trained, we can use it to generate new text, one character at a time. This process is known as inference or sampling. We begin by providing the network with an initial “seed” sequence (e.g., a few characters or words). The RNN processes this seed and outputs a probability distribution for the next character, as shown in <a href="#fig-rnn-LLM" class="quarto-xref">Figure&nbsp;<span>8.8</span></a>.</p>
<p>To generate the next character, we sample from this probability distribution. This means characters with a higher predicted probability are more likely to be chosen, but there is still an element of randomness. The newly generated character is then appended to the sequence, and this new, longer sequence is fed back into the RNN to generate the character after that. This process is repeated to generate entire sentences or even paragraphs of text.</p>
<div id="fig-rnn-LLM" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-LLM-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-5.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-LLM-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.8: The process of generating text one character at a time using a trained RNN.
</figcaption>
</figure>
</div>
<p>This fun application was popularised in a seminal <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/#fun-with-rnns">blog post</a> by Andrej Karpathy. We recommend visiting the post for more examples and insights into the power of RNNs. As we will see in later chapters, this fundamental idea of sequential prediction is at the heart of modern Large Language Models (LLMs).</p>
</section>
</section>
<section id="training-back-propagation-through-time" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="training-back-propagation-through-time"><span class="header-section-number">8.3</span> Training: Back-Propagation Through Time</h2>
<p>To train an RNN, we need a method to calculate the gradients of the loss function with respect to the network’s parameters. Since the parameters are shared across all time steps, the gradient at a particular time step depends on all previous time steps.</p>
<p>The standard algorithm for this is <strong>Back-Propagation Through Time (BPTT)</strong>. It works by first unrolling the RNN into a deep feedforward network, as shown in <a href="#fig-rnn-fig-rnn-BPTT" class="quarto-xref">Figure&nbsp;<span>8.9</span></a>. Once unrolled, we can apply the standard back-propagation algorithm to calculate the gradients. The total gradient for a given parameter is the sum of the gradients for that parameter at each time step.</p>
<div id="fig-rnn-fig-rnn-BPTT" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-fig-rnn-BPTT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-8.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-fig-rnn-BPTT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.9: Back-Propagation Through Time (BPTT) involves unrolling the RNN and applying standard back-propagation.
</figcaption>
</figure>
</div>
<p>However, BPTT has its challenges. Unrolling the network for a long sequence can result in a very deep computational graph, which can consume a large amount of GPU memory. Furthermore, the process is inherently sequential, making it difficult to parallelise and slow to train.</p>
<p>To mitigate these issues, a common strategy is to split the long sequence into smaller chunks and apply BPTT only on these truncated parts. This approach is called <strong>Truncated Back-Propagation Through Time (TBPTT)</strong>, illustrated in <a href="#fig-rnn-truncated-BPTT" class="quarto-xref">Figure&nbsp;<span>8.10</span></a>. While this makes training more manageable, it comes at the cost of the network’s ability to learn dependencies that span longer than the chunk size.</p>
<div id="fig-rnn-truncated-BPTT" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-truncated-BPTT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-9.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-truncated-BPTT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.10: In Truncated BPTT, the RNN is unrolled for only a fixed number of time steps.
</figcaption>
</figure>
</div>
</section>
<section id="dealing-with-long-sequences" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="dealing-with-long-sequences"><span class="header-section-number">8.4</span> Dealing with Long Sequences</h2>
<p>When unrolled, recurrent networks can become very deep. As with any deep network, training with gradient descent is susceptible to the <strong>vanishing and exploding gradient problems</strong>. As the error is propagated back through many time steps, the gradients can either shrink exponentially until they become negligible (vanish) or grow exponentially until they become unstable (explode). This makes it very difficult for simple RNNs to learn long-range dependencies in the data.</p>
<p>For this reason, the simple RNN architecture is rarely used in practice. Instead, we resort to more sophisticated RNN architectures that were specifically designed to address this issue, namely Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU).</p>
<section id="lstm" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="lstm"><span class="header-section-number">8.4.1</span> LSTM</h3>
<p>The <strong>Long Short-Term Memory (LSTM)</strong> architecture was introduced in 1997 by Sepp Hochreiter and Jürgen Schmidhuber <span class="citation" data-cites="lstm">(<a href="references.html#ref-lstm" role="doc-biblioref">Hochreiter and Schmidhuber 1997</a>)</span> precisely to combat the vanishing and exploding gradient problems. LSTM cells (see <a href="#fig-rnn-lstm" class="quarto-xref">Figure&nbsp;<span>8.11</span></a>) replace the simple hidden layer of a standard RNN. They introduce a more complex internal structure that includes a separate cell state and a series of “gates” that regulate the flow of information.</p>
<p>These gates—the forget gate, input gate, and output gate—allow the network to selectively add or remove information from the cell state, enabling it to remember information for very long periods. After their potential was realised around 2014, major technology companies like Google, Apple, and Microsoft began using LSTMs extensively in products for speech recognition and machine translation.</p>
<div id="fig-rnn-lstm" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-lstm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/LSTM.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-lstm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.11: The internal architecture of a Long Short-Term Memory (LSTM) cell. (Figure by François Deloche).
</figcaption>
</figure>
</div>
<div id="seealso-lstm" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
See Also
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>S. Hochreiter and J. Schmidhuber (1997). “Long short-term memory” <a href="https://goo.gl/hhBNRE">original paper</a></li>
<li>Keras’s <a href="https://keras.io/api/layers/recurrent_layers/lstm">LSTM documentation</a></li>
<li>See also Brandon’s Rohrer’s <a href="https://youtu.be/WCUNPb-5EYI">video</a></li>
<li>and colah’s <a href="https://goo.gl/uc7gbn">blog</a></li>
</ul>
</div>
</div>
</section>
<section id="gru" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="gru"><span class="header-section-number">8.4.2</span> GRU</h3>
<p>The <strong>Gated Recurrent Unit (GRU)</strong> was introduced in 2014 <span class="citation" data-cites="gru">(<a href="references.html#ref-gru" role="doc-biblioref">Chung et al. 2014</a>)</span> as a simpler alternative to the LSTM. GRUs combine the forget and input gates into a single “update gate” and merge the cell state and hidden state. This results in a model that is computationally more efficient (faster to train) because it has fewer parameters than an LSTM.</p>
<p>The performance of GRUs is often comparable to that of LSTMs. They may perform slightly better on smaller datasets but can be outperformed by LSTMs on larger, more complex problems. The architecture is shown in <a href="#fig-rnn-gru" class="quarto-xref">Figure&nbsp;<span>8.12</span></a>.</p>
<div id="fig-rnn-gru" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-gru-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/GRU.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-gru-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.12: The internal architecture of a Gated Recurrent Unit (GRU) cell. (Figure by François Deloche).
</figcaption>
</figure>
</div>
<div id="seealso-gru" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
See Also
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>J. Chung, C. Gulcehre, K. Cho and Y. Bengio (2014). “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling”. (<a href="https://arxiv.org/abs/1412.3555">original paper</a>)</li>
<li>Keras <a href="https://keras.io/api/layers/recurrent_layers/gru/">GRU documentation</a></li>
</ul>
</div>
</div>
</section>
<section id="gated-units" class="level3" data-number="8.4.3">
<h3 data-number="8.4.3" class="anchored" data-anchor-id="gated-units"><span class="header-section-number">8.4.3</span> Gated Units</h3>
<p>Without delving too deeply into the equations of LSTMs and GRUs, it is useful to understand the core concept they introduce: <strong>gated units</strong>. So far, the primary way we have combined information from two units, <span class="math inline">u_1</span> and <span class="math inline">u_2</span>, has been through a linear combination, <span class="math inline">w_1u_1 + w_2u_2</span>. Gating provides an alternative mechanism based on element-wise multiplication.</p>
<div id="fig-rnn-gated-units" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-gated-units-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-gating-units.svg" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-gated-units-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.13: A gated unit, where <span class="math inline">u_1</span> controls the flow of information from <span class="math inline">u_2</span>.
</figcaption>
</figure>
</div>
<p>A gate is typically a vector produced by a sigmoid activation function, <span class="math inline">\sigma(u_1)</span>, whose values range between 0 and 1. This gate then acts as a filter on another vector, <span class="math inline">u_2</span>. When a value in the gate is close to 0, the corresponding feature in <span class="math inline">u_2</span> is blocked. When it is close to 1, the feature is allowed to pass through.</p>
<p>To build some intuition, consider a text processing example where <span class="math inline">u_2</span> is a vector representing the probability of the next word:</p>
<p><span class="math display">
u_2 = \begin{bmatrix} \vdots \\ p(\text{bat --- the animal}) = 0.4
  \\ p(\text{bat --- the stick}) = 0.3
  \\ \vdots \end{bmatrix}
</span></p>
<p>Here, the word “bat” is ambiguous. The role of the gate, <span class="math inline">\sigma(u_1)</span>, which is computed from the prior context, could be to resolve this ambiguity:</p>
<p><span class="math display">
\sigma(u_1) = \begin{bmatrix} \vdots \\ 0.96 \\ 0.04
  \\ \vdots \end{bmatrix}
</span></p>
<p>Multiplying the two vectors element-wise effectively filters out the unwanted meaning:</p>
<p><span class="math display">
u_2 \odot \sigma(u_1) = \begin{bmatrix} \vdots \\ 0.4 \\ 0.3 \\ \vdots \end{bmatrix} \odot \begin{bmatrix} \vdots \\ 0.96 \\ 0.04 \\ \vdots \end{bmatrix} =  \begin{bmatrix} \vdots \\ 0.384 \\ 0.012 \\ \vdots \end{bmatrix}
</span></p>
<p>In LSTMs and GRUs, this gating mechanism is used to control the cell state, allowing the network to learn what information to store, what to forget, and what to output at each time step.</p>
</section>
</section>
<section id="application-image-caption-generator" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="application-image-caption-generator"><span class="header-section-number">8.5</span> Application: Image Caption Generator</h2>
<p>A powerful application that combines computer vision and natural language processing is the <strong>Image Caption Generator</strong>. This model takes an image as input and automatically generates a textual description.</p>
<div id="seealso-image-captioning" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
See Also
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>O. Vinyals, A. Toshev, S. Bengio and D. Erhan (2015). ``Show and tell: A neural image caption generator’’ <a href="https://arxiv.org/abs/1411.4555">original paper</a> <span class="citation" data-cites="showandtell">(<a href="references.html#ref-showandtell" role="doc-biblioref">Vinyals et al. 2015</a>)</span></li>
<li>Google Research Blog <a href="https://goo.gl/U88bDQ">post</a></li>
</ul>
</div>
</div>
<p>The process begins (see <a href="#fig-rnn-captioning" class="quarto-xref">Figure&nbsp;<span>8.14</span></a>) by using a pre-trained Convolutional Neural Network (CNN), such as VGG or ResNet, to extract a rich set of visual features from the input image.</p>
<p>We typically remove the final classification layer of the CNN, as we are interested in the high-level feature representation from one of the last fully connected layers, not the final class prediction.</p>
<div id="fig-rnn-captioning" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnn-captioning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/rnn-17.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn-captioning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.14: Image Captioning. First the input impage is mapped into a vector using a pre-trained network like VGG. This vector is used as the context for the first step of a RNN. The RNN’s output makes predictions about the next word token. Sampling ends when the special token <code>&lt;end&gt;</code> is emitted.
</figcaption>
</figure>
</div>
<p>This feature vector, which serves as a numerical summary of the image’s content, is then fed as the initial input to an RNN (typically an LSTM or GRU). The RNN’s task is to generate the caption, one word at a time.</p>
<p>The RNN is trained to predict the next word in the caption, given the image features and the words generated so far. During inference, we continue this process, feeding the previously generated word back as input to predict the next, until a special <code>&lt;end&gt;</code> token is generated.</p>
</section>
<section id="takeaways" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="takeaways"><span class="header-section-number">8.6</span> Takeaways</h2>
<p>Recurrent Neural Networks provide a powerful framework for modelling sequential data, finding applications in time series analysis, text processing, and video analysis. However, simple RNNs are difficult to train due to the vanishing and exploding gradient problems, which limit their ability to capture long-range dependencies.</p>
<p>Gated architectures like LSTMs and GRUs were developed to overcome these limitations. By using gating mechanisms to control the flow of information, they have made the training of deep recurrent models far more stable and effective. These models became the standard for many language-based tasks, including machine translation, text generation, and image captioning.</p>
</section>
<section id="limitations-of-rnns-and-the-rise-of-transformers" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="limitations-of-rnns-and-the-rise-of-transformers"><span class="header-section-number">8.7</span> Limitations of RNNs and the Rise of Transformers</h2>
<p>Despite their success, RNNs have fundamental limitations. Their inherently recurrent nature, processing data one step at a time, prevents effective parallelisation. This makes them slow to train on very long sequences.</p>
<p>Perhaps more critically, RNNs and LSTMs are not well-suited for transfer learning in the same way as CNNs. It is difficult to pre-train a general-purpose RNN on a massive dataset and then fine-tune it for a new task. Consequently, most RNN applications require training from scratch, which demands large amounts of task-specific data and significant computational resources.</p>
<p>The 2017 landmark paper “Attention Is All You Need” <span class="citation" data-cites="attention">(<a href="references.html#ref-attention" role="doc-biblioref">Vaswani et al. 2017</a>)</span> introduced the <strong>Transformer</strong> architecture, which has since ended the predominance of RNNs in natural language processing. Transformers, built upon the <strong>Attention Mechanism</strong>, dispense with recurrence entirely. Their design allows for massive parallelisation and has proven exceptionally effective for transfer learning. This has enabled the creation of powerful pre-trained models like BERT and GPT, which can be adapted to a wide range of tasks with minimal fine-tuning. This is why we will cover these in the next chapters.</p>
<p>… but good ideas never die. Recurrent approaches made a comeback in late 2023 with <em>Mamba</em>, an architecture demonstrating that state-space models with recurrent properties can compete with, and sometimes outperform, Transformers, particularly in terms of computational efficiency during inference. This shows that the principles of recurrence remain an active and evolving area of research.</p>
<div id="seealso-mamba" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
See Also
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Albert Gu, Tri Dao (2023). “Mamba: Linear-Time Sequence Modeling with Selective State Spaces”. <a href="https://arxiv.org/abs/2312.00752">original paper</a></li>
<li>see also this <a href="https://tinyurl.com/4ub385ye">tutorial</a></li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-gru" class="csl-entry" role="listitem">
Chung, Junyoung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014. <span>“Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.”</span> In <em>NIPS 2014 Workshop on Deep Learning, December 2014</em>.
</div>
<div id="ref-lstm" class="csl-entry" role="listitem">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Computation</em> 9 (8): 1735–80.
</div>
<div id="ref-attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett. Vol. 30. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.
</div>
<div id="ref-showandtell" class="csl-entry" role="listitem">
Vinyals, Oriol, Alexander Toshev, Samy Bengio, and Dumitru Erhan. 2015. <span>“Show and Tell: A Neural Image Caption Generator.”</span> In <em>CVPR</em>, 3156–64. IEEE Computer Society. <a href="http://dblp.uni-trier.de/db/conf/cvpr/cvpr2015.html#VinyalsTBE15">http://dblp.uni-trier.de/db/conf/cvpr/cvpr2015.html#VinyalsTBE15</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter-07-advances-in-network-architectures.html" class="pagination-link" aria-label="Advances in Network Architectures">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advances in Network Architectures</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter-09-generative-models.html" class="pagination-link" aria-label="An Introduction to Generative Models">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">An Introduction to Generative Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, François Pitié</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>